# Desafio Vertical LogÃ­stica - Node.js

## SumÃ¡rio
1. [DescriÃ§Ã£o da SoluÃ§Ã£o](#1---descriÃ§Ã£o-da-soluÃ§Ã£o)
2. [Linguagem](#2---linguagem)
3. [Banco de Dados](#3---banco-de-dados)
4. [Arquitetura](#4---arquitetura-utilizada)
5. [Bibliotecas](#5---ferramentas-e-frameworks-utilizados)
6. [Modelagem](#6---modelagem-dos-dados)
7. [Como Rodar](#7---como-rodar-localmente-e-por-docker)
8. [Testes](#8---testes)
8. [DocumentaÃ§Ã£o](#9---documentaÃ§Ã£o)



## 1 - DescriÃ§Ã£o da SoluÃ§Ã£o
Esta REST API foi criada para mostrar um pouco a minha forma de resolver problemas do cotidiano em Node.js.
Trata-se da resoluÃ§Ã£o do desafio tÃ©cnico da Vertical LogÃ­stica do **LuizaLabs**.
O desafio consiste em integrar dois sistemas: um sistema legado que possui
pedidos desnormalizados deve ser integrado em um outro que seja capaz de transformar esses
arquivos .txt em JSON normalizado e disponibilizar para consulta.

![fluxo](readmeImages/fluxo.png)

### Jornada
As etapas realizadas para o desenvolvimento da soluÃ§Ã£o envolveram projeto, modelagem, teste e muita mÃ£o na massa. Tendo como um dos pilares a **simplicidade**, foi idealizada uma API robusta, de fÃ¡cil manutenÃ§Ã£o e escalÃ¡vel.
- **ImportaÃ§Ã£o de pedidos**: para essa soluÃ§Ã£o, foi utilizado o conceito de node streams, uma forma nativa e eficiente de processar grandes volumes de dados de maneira contÃ­nua e sem precisar carregar tudo na memÃ³ria de uma vez. Com streams, os dados sÃ£o lidos e processados em pedaÃ§os menores (chunks) Ã  medida que sÃ£o recebidos, ou seja, sob demanda. O dado ao ser recebido Ã© tratado e persistido no MongoDB, por meio de um pipeline. Com essa tÃ©cnica foi possÃ­vel processar os dados em *backgroud*, sem prender o usuÃ¡rio e sem sobrecarregar a aplicaÃ§Ã£o.
- **Busca de pedidos**: Foi utilizado o MongoDB para persistÃªncia dos dados, para que com uma simples agregaÃ§Ã£o os dados consigam ser retornados de forma eficiente e performÃ¡tica. Ãndices de order_id e date foram criados.

## 2 - Linguagem
A linguagem utilizada foi **TypeScript**. TypeScript foi escolhido por fornecer tipagem estÃ¡tica, o que ajuda a evitar muitos erros comuns durante o desenvolvimento e melhora a manutenÃ§Ã£o do cÃ³digo a longo prazo.

## 3 - Banco de Dados
O banco de dados utilizado foi o **MongoDB** juntamente com o ODM **Mongoose**. 

### Motivos para Utilizar MongoDB:
- **Flexibilidade de Esquema**: MongoDB Ã© um banco de dados NoSQL que permite uma modelagem de dados flexÃ­vel e dinÃ¢mica, ideal para trabalhar com dados que podem ter estruturas variadas ao longo prazo. Imagine que a partir de um certo ponto novos atributos existam (ex: cÃ³digo do produto)
- **Desempenho**: MongoDB Ã© conhecido por seu alto desempenho em operaÃ§Ãµes de leitura e escrita, o que Ã© essencial para aplicaÃ§Ãµes que lidam com grandes volumes de dados - caracterÃ­stica da importaÃ§Ã£o de carga do desafio.
- **Escalabilidade**: MongoDB oferece escalabilidade horizontal, permitindo que a aplicaÃ§Ã£o cresÃ§a conforme a demanda aumenta.
- **Objetos profundos e simplicidade**: MongoDB permite adiÃ§Ã£o de objetos profundos, evitando a necessidade por exemplo de se ter criado uma nova tabela para produtos, o que no contexto da manipulaÃ§Ã£o de dados evita-se operaÃ§Ãµes de JOIN (ou lookup), oferecendo ganho de performance e simplicidade nos dados.

### Motivos para Utilizar Mongoose:
- **Modelagem de Dados**: Mongoose fornece uma camada de abstraÃ§Ã£o sobre o MongoDB, permitindo a definiÃ§Ã£o de esquemas de dados com validaÃ§Ã£o e tipos, o que Ã© muito Ãºtil em um projeto TypeScript.
- **ValidaÃ§Ã£o**: Mongoose permite a definiÃ§Ã£o de validaÃ§Ãµes complexas diretamente nos esquemas, garantindo a integridade dos dados.
- **Facilidade de Uso**: Mongoose simplifica a interaÃ§Ã£o com o MongoDB, fornecendo uma API intuitiva para operaÃ§Ãµes CRUD (Create, Read, Update, Delete).


## 4 - Arquitetura Utilizada
A arquitetura utilizada Ã© baseada nos conceitos do SOLID em [**Clean Architecture (Robert C. Martin)**](https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html).
- Baixo acoplamento
- Testes
- SeparaÃ§Ã£o de interesses
### Estrutura geral do Projeto
```
â”£ ğŸ“‚classes
â”ƒ â”£ ğŸ“œcommonFields.ts
â”ƒ â”— ğŸ“œorder.ts
â”£ ğŸ“‚commons
â”ƒ â”£ ğŸ“‚interfaces
â”ƒ â”ƒ â”£ ğŸ“œbase.ts
â”ƒ â”ƒ â”£ ğŸ“œorder.ts
â”ƒ â”ƒ â”— ğŸ“œproduct.ts
â”ƒ â”£ ğŸ“‚requests
â”ƒ â”ƒ â”— ğŸ“œorder.ts
â”ƒ â”— ğŸ“‚validator
â”ƒ   â”£ ğŸ“œorder.ts
â”ƒ   â”— ğŸ“œschemas.ts
â”£ ğŸ“‚controllers
â”ƒ â”— ğŸ“œorder.ts
â”£ ğŸ“‚implementations
â”ƒ â”— ğŸ“œorder.ts
â”£ ğŸ“‚models
â”ƒ â”— ğŸ“œorder.ts
â”£ ğŸ“‚plugins
â”ƒ â”£ ğŸ“œcommonFields.ts
â”ƒ â”— ğŸ“œerrors.ts
â”£ ğŸ“‚routes
â”ƒ â”£ ğŸ“œindex.ts
â”ƒ â”— ğŸ“œorder.ts
â”£ ğŸ“‚services
â”ƒ â”£ ğŸ“œdatabase.ts
â”ƒ â”£ ğŸ“œenvironment.ts
â”ƒ â”£ ğŸ“œerrorHandler.ts
â”ƒ â”— ğŸ“œvalidator.ts
â”£ ğŸ“‚tests
â”ƒ â”— ğŸ“œorders.test.ts
â”£ ğŸ“‚utils
â”ƒ â”— ğŸ“œorderService.ts
â”£ ğŸ“œapp.ts
â”£ ğŸ“œindex.ts
â”— ğŸ“œswagger.json
```
### DefiniÃ§Ãµes
- Classes: definiÃ§Ãµes das classes que serÃ£o consumidas nas implementaÃ§Ãµes para instanciar os objetos a serem persistidos.
- Commons: definiÃ§Ã£o de interfaces, requisiÃ§Ãµes e validaÃ§Ãµes. Podem ser facilmente consumidas em conjunto com o frontend, evitando duplicidade de cÃ³digo.
- Controller: definiÃ§Ã£o dos endpoints.
- Implementations: implementaÃ§Ã£o dos endpoints - aplicaÃ§Ã£o de regras de negÃ³cios.
- Models: definiÃ§Ã£o de schemas do banco de dados
- Plugins: mÃ©todos e funÃ§Ãµes fixas para o MongoDB
- Routes: definiÃ§Ã£o das rotas
- Services: conexÃµes externas e adaptadores
- Tests: testes unitÃ¡rios e de integraÃ§Ã£o
- Utils: funÃ§Ãµes especÃ­ficas consumidas nas implementaÃ§Ãµes


## 5 - Ferramentas e Frameworks Utilizados
- **Express**: Framework para construÃ§Ã£o de APIs em Node.js.
- **Mongoose**: Biblioteca para modelagem de dados MongoDB.
- **Zod**: Biblioteca para validaÃ§Ã£o de esquemas.
- **Multer**: Middleware para manipulaÃ§Ã£o de arquivos multipart/form-data.
- **Swagger**: Ferramenta para documentaÃ§Ã£o de APIs.
- **Jest**: Framework de testes.
- **Supertest**: Biblioteca para testes de integraÃ§Ã£o de APIs.
- **CORS**: Biblioteca utilizada para controle de acesso Ã  API.
- **Node Diagnostics Report**: serviÃ§o nativo do node, utilizado para gerar logs de relatÃ³rio quando exceÃ§Ãµes nÃ£o mapeadas e fatalidades ocorrerem na aplicaÃ§Ã£o.
- **Autocannon**: Ferramenta utilizada para simular operaÃ§Ãµes de carga nas rotas. 

## 6 - Modelagem dos Dados
Os dados sÃ£o modelados utilizando Mongoose e Zod para validaÃ§Ã£o. A estrutura bÃ¡sica dos dados de pedidos Ã© a seguinte:
- **Order**:
  - `order_id`: NÃºmero do pedido.
  - `user_id`: NÃºmero do usuÃ¡rio.
  - `name`: Nome do pedido.
  - `date`: Data do pedido.
  - `product`: Produto associado ao pedido.
  - `total`: Total do pedido.
  - `status`: Objeto com data de criaÃ§Ã£o, data de update e data de deleÃ§Ã£o (trabalhando conceitos de soft-delete)

![jsonExemplo](readmeImages/jsonExample.png)

### MotivaÃ§Ã£o
A persistÃªncia dos dados da forma mostrada acima foi pensada tendo em vista a necessidade do processamento sob demanda na importaÃ§Ã£o de pedidos. Com essa estrutura, uma mÃ­nima manipulaÃ§Ã£o foi feita nos dados de entrada, tornando o processo mais simplificado e seguro.
A outra razÃ£o pela modelagem em si Ã© o fato da mesma permitir diferentes manipulaÃ§Ãµes nos dados em momentos de agregaÃ§Ã£o, o que possibilita retornos distintos e personalizÃ¡veis.

## 7 - Como Rodar Localmente e por Docker
### Rodar Localmente
1. Clone o repositÃ³rio:
   ```sh
   git clone https://github.com/thibaraujo/LuizaLabs-Desafio-Vertical-Logistica.git
   cd seu-repositorio
2. npm install
    ```sh
    npm install
3. Configure as variÃ¡veis de ambiente no arquivo **.env**
4. Execute os testes **npm run test**
    ```sh
    npm run test
5. Execute a aplicaÃ§Ã£o **npm run dev** ou **npm run start**
    ```sh
    npm run dev
### Rodar no Docker
1. No terminal
    ```sh
    docker build -t nome-da-imagem
2. No terminal
    ```sh
    docker run -p 8000:8000 nome-da-imagem
## 8 - Testes
Os testes sÃ£o escritos utilizando Jest e Supertest
### Rodar teste
1. Certifique de ter instalado as dependÃªncias do projeto.
2. Use o comando no terminal
    ```sh
    npm run test

### Mapeamento de teste
O teste, apÃ³s executado, retorna a **cobertura** total obtida. Pode-se analisar na imagem em que cerca de 90% da aplicaÃ§Ã£o foi mapeada nos testes.

![Cobertura](readmeImages/testsCoverage.png)

### Teste de carga com o Autocannon
Foi utilizado a biblioteca autocannon para testar mÃºltiplas conexÃµes e requisiÃ§Ãµes simultÃ¢neas Ã s rotas. Com seu retorno estatÃ­stico Ã© possÃ­vel entender as capacidades e limitaÃ§Ãµes de cada rota.

- **100 conexÃµes, sem filtro**
![autocannonGet](readmeImages/autocannon-100.png)

- **100 conexÃµes, filtro de data final**

![autocannonGet2](readmeImages/autocannon-endDate-100.png)


## 9 - DocumentaÃ§Ã£o
A documentaÃ§Ã£o da API estÃ¡ disponÃ­vel no Swagger e no Postman.
### Acesso Swagger
1. Inicie o servidor
2. navegue atÃ© http://localhost:8000/api-docs
### Acesso Postman
1. Acesse o link https://www.postman.com/telecoms-geologist-97212053/workspace/luizalabs-logstica/folder/29387797-864478c2-f33c-49c2-83c0-e7438450b584?action=share&creator=29387797&ctx=documentation

